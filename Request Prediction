{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework2_SUN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmmaSun19950308/LendingClub_Request_Prediction/blob/master/Homework2_SUN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LKmVMSGL6o8",
        "colab_type": "text"
      },
      "source": [
        "# **Homework 2-SUN Siyang**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzFBHtFHRBkH",
        "colab_type": "text"
      },
      "source": [
        "# Download the Data \n",
        "Keep this if you are working in Google Colab. Delete this if you are working on your own computer and have the data downloaded already. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD8xgRYrRAV3",
        "colab_type": "code",
        "outputId": "29f34342-fa3a-4c22-8242-79c120544eb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=0B5qTk6DHjanhOV9LRE5DY3l1T2pGemVBNTVQVzVsMlFCcHF3' -O lendingclub.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-15 13:50:45--  https://docs.google.com/uc?export=download&id=0B5qTk6DHjanhOV9LRE5DY3l1T2pGemVBNTVQVzVsMlFCcHF3\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.204.113, 172.217.204.138, 172.217.204.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.204.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-10-5c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/htt4lfo05e2hctfd0numvmfj9t83i7sg/1581774300000/09819396713149841370/*/0B5qTk6DHjanhOV9LRE5DY3l1T2pGemVBNTVQVzVsMlFCcHF3?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-02-15 13:50:51--  https://doc-10-5c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/htt4lfo05e2hctfd0numvmfj9t83i7sg/1581774300000/09819396713149841370/*/0B5qTk6DHjanhOV9LRE5DY3l1T2pGemVBNTVQVzVsMlFCcHF3?e=download\n",
            "Resolving doc-10-5c-docs.googleusercontent.com (doc-10-5c-docs.googleusercontent.com)... 172.217.203.132, 2607:f8b0:400c:c07::84\n",
            "Connecting to doc-10-5c-docs.googleusercontent.com (doc-10-5c-docs.googleusercontent.com)|172.217.203.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘lendingclub.csv’\n",
            "\n",
            "lendingclub.csv         [ <=>                ]   6.03M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2020-02-15 13:50:51 (107 MB/s) - ‘lendingclub.csv’ saved [6325329]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN6W49dCdBUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.formula.api as smf\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, cohen_kappa_score, confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split, KFold,GridSearchCV,StratifiedKFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu_t71vorQIf",
        "colab_type": "code",
        "outputId": "040bac97-e447-4aa5-c201-67da2b6408c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# open the dataset and name it as \"lending\"\n",
        "lending = pd.read_csv(\"lendingclub.csv\") \n",
        "\n",
        "# Convert prediction variable \"outcome\" to be a binary variable\n",
        "lending[\"loan_outcome\"] = lending[\"outcome\"] == \"accept\"\n",
        "# lending.groupby(\"loan_outcome\").size()\n",
        "# There are 71,858 loan requests failed while 9,245 loan requests were accepted.\n",
        "\n",
        "lending.head()\n",
        "# print(lending.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>amount</th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>fico</th>\n",
              "      <th>dti</th>\n",
              "      <th>zip</th>\n",
              "      <th>state</th>\n",
              "      <th>emp_length</th>\n",
              "      <th>policy_code</th>\n",
              "      <th>year</th>\n",
              "      <th>outcome</th>\n",
              "      <th>loan_outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2500.0</td>\n",
              "      <td>Dec-2011</td>\n",
              "      <td>bike</td>\n",
              "      <td>740.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>309xx</td>\n",
              "      <td>GA</td>\n",
              "      <td>&lt; 1 year</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>accept</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12000.0</td>\n",
              "      <td>Dec-2011</td>\n",
              "      <td>Consolidation</td>\n",
              "      <td>675.0</td>\n",
              "      <td>10.78</td>\n",
              "      <td>913xx</td>\n",
              "      <td>CA</td>\n",
              "      <td>10+ years</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>accept</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21000.0</td>\n",
              "      <td>Dec-2011</td>\n",
              "      <td>Debt Cleanup</td>\n",
              "      <td>705.0</td>\n",
              "      <td>13.22</td>\n",
              "      <td>335xx</td>\n",
              "      <td>FL</td>\n",
              "      <td>10+ years</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>accept</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31825.0</td>\n",
              "      <td>Dec-2011</td>\n",
              "      <td>Debt Consolidation Loan</td>\n",
              "      <td>760.0</td>\n",
              "      <td>14.03</td>\n",
              "      <td>080xx</td>\n",
              "      <td>NJ</td>\n",
              "      <td>5 years</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>accept</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12000.0</td>\n",
              "      <td>Dec-2011</td>\n",
              "      <td>Debt Consolidation</td>\n",
              "      <td>725.0</td>\n",
              "      <td>16.70</td>\n",
              "      <td>088xx</td>\n",
              "      <td>NJ</td>\n",
              "      <td>10+ years</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>accept</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    amount      date                    title  ...  year  outcome loan_outcome\n",
              "0   2500.0  Dec-2011                     bike  ...  2011   accept         True\n",
              "1  12000.0  Dec-2011            Consolidation  ...  2011   accept         True\n",
              "2  21000.0  Dec-2011             Debt Cleanup  ...  2011   accept         True\n",
              "3  31825.0  Dec-2011  Debt Consolidation Loan  ...  2011   accept         True\n",
              "4  12000.0  Dec-2011       Debt Consolidation  ...  2011   accept         True\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkkuBmvYFkV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a function to check outcome on different labels of certain feature\n",
        "# this function will be used later\n",
        "def evaluate_split_on_feature(df, column):\n",
        "    for label in df[column].unique():\n",
        "        matched_rows = df.loc[df[column] == label]\n",
        "        counts = matched_rows[\"outcome\"].value_counts()\n",
        "        counts = 100 * counts / len(matched_rows)\n",
        "        print(label)\n",
        "        print(counts)\n",
        "        print(\"------------------\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EavIoGONuw9Y",
        "colab_type": "text"
      },
      "source": [
        "### Build original decision tree used in HW1\n",
        "In this decision tree, I used feature \"fico\" and \"norm_emp_length\". \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xyu3WC2fWJv_",
        "colab_type": "code",
        "outputId": "1a84a7d1-fc0b-4543-8cde-b31ce9fcf0dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# create feature \"norm_emp_length\".\n",
        "def norm_emp_length(x):\n",
        "    if x == \"< 1 year\":\n",
        "        return \"short employment\"\n",
        "    if x != \"< 1 year\":\n",
        "        return \"long employment\"\n",
        "    \n",
        "lending[\"norm_emp_length\"] = lending[\"emp_length\"].apply(norm_emp_length)\n",
        "\n",
        "# create the feature set\n",
        "original_features = [\"fico\",\"norm_emp_length\"]\n",
        "\n",
        "# Create a dummyset with only the features in our feature set\n",
        "X = lending.loc[:, original_features]\n",
        "X = pd.get_dummies(X)\n",
        "y = lending[\"loan_outcome\"]\n",
        "\n",
        "# Use scikit-learn to create train/test split and train our decision tree\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=123)\n",
        "model = DecisionTreeClassifier(criterion=\"entropy\", random_state=123).fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate quality metrics\n",
        "accuracy = 100*accuracy_score(y_test, y_pred)\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "    \n",
        "print(f\"Results for original features:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(f\"\\nThe quality metrics are as follow: \\nAccuracy: {accuracy:.1f}% Kappa: {kappa:.3f} Precision: {precision:.3f} Recall: {recall:.3f} \\n\")\n",
        "print(f\"In this model, tree contains {model.get_n_leaves()} leaves\")\n",
        "print(f\"In this model, the depth of tree is {model.get_depth()}\")\n",
        "print(f\"The hyperparameters are: \\n{model.get_params(deep = True)}\")\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for original features:\n",
            "[[13979   370]\n",
            " [  197  1675]]\n",
            "\n",
            "The quality metrics are as follow: \n",
            "Accuracy: 96.5% Kappa: 0.835 Precision: 0.819 Recall: 0.895 \n",
            "\n",
            "In this model, tree contains 148 leaves\n",
            "In this model, the depth of tree is 69\n",
            "The hyperparameters are: \n",
            "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 123, 'splitter': 'best'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym3NhRYWEqN9",
        "colab_type": "text"
      },
      "source": [
        "# **Answer to Question 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7J5y94Ef5Nj",
        "colab_type": "text"
      },
      "source": [
        "## 1.  Create a new feature: region\n",
        "\n",
        "\n",
        "*   The United States Census Bureau defines four statistical regions: West, South, Northeast and Midwest. \n",
        "*   Here, the distribution of the variable “state” is missing some of values, such as ND, NE, ID. Therefore, it is necessary to transform “state” to “region” as a normalized, nominal variable. \n",
        "*   In this way, there are 19,754 observations in West, 30,513 observations in South, 17,546 observations in Northeast and 13,290 observations in Midwest, which seems like to be more intuitive. \n",
        "\n",
        "*   When it comes to the result of model comparisons, I create three feature sets: \n",
        "\n",
        "> 1.   original feature set\n",
        "> 2.   original feature set + state \n",
        "> 3.   original feature set + region\n",
        "\n",
        "\n",
        "*   As expected, the model with **original feature set + region performs better** than the model with original feature set + state, indicated by the accuracy rate. However, **the original one is still the best**.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTC162a6rR_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a function to create \"region\"\n",
        "def set_region(x):\n",
        "    if x == \"AK\" or x == \"WY\" or x == \"WA\" or x == \"UT\" or x == \"OR\" or x == \"AZ\" or x == \"CA\" or x == \"CO\" or x == \"HI\" or x == \"ID\" or x == \"MT\" or x == \"NM\" or x == \"NV\":\n",
        "        return \"West\"\n",
        "    if x == \"AL\" or x == \"WV\" or x == \"VA\" or x == \"TN\" or x == \"TX\" or x == \"SC\" or x == \"AR\" or x == \"OK\" or x == \"DC\" or x == \"DE\" or x == \"FL\" or x == \"GA\" or x == \"KY\" or x == \"LA\" or x == \"MD\" or x == \"MS\" or x == \"NC\":\n",
        "        return \"South\"\n",
        "    if x == \"CT\" or x == \"VT\" or x == \"PA\" or x == \"RI\" or x == \"MA\" or x == \"ME\" or x == \"NH\" or x == \"NJ\" or x == \"NY\":\n",
        "        return \"Northeast\"\n",
        "    if x == \"IA\" or x == \"WI\" or x == \"SD\" or x == \"IL\" or x == \"IN\" or x == \"KS\" or x == \"MI\" or x == \"MN\" or x == \"MO\" or x == \"ND\" or x == \"NE\" or x == \"OH\":\n",
        "        return \"Midwest\"\n",
        "\n",
        "lending[\"region\"] = lending[\"state\"].apply(set_region)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFDaOqkzFQQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_region(state):\n",
        "  if state in [\"AK\" , \"WY\" , \"WA\" , \"UT\" , \"OR\" , \"AZ\" , \"CA\" , \"CO\" , \"HI\" ,\"ID\" ,\"MT\" , \"NM\" , \"NV\"]:\n",
        "      return \"West\"\n",
        "  elif state in [\"AL\" , \"WV\" , \"VA\" ,\"TN\" ,\"TX\" , \"SC\" , \"AR\" ,\"OK\" ,\"DC\" , \"DE\" ,\"FL\" ,\"GA\" , \"KY\",\"LA\",\"MD\",\"MS\" , \"NC\"]:\n",
        "      return \"South\"\n",
        "  elif state in [ \"CT\" , \"VT\" , \"PA\", \"RI\", \"MA\" , \"ME\" , \"NH\" , \"NJ\" , \"NY\"]:\n",
        "      return \"Northeast\"\n",
        "  else:\n",
        "      return \"Midwest\"\n",
        "\n",
        "lending[\"region\"] = lending[\"state\"].apply(set_region)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E29QOs-IH8c6",
        "colab_type": "code",
        "outputId": "7ac6185d-6365-406a-a00b-0a27b9a7c1f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# compare the distribution of \"region\" and \"state\"\n",
        "print(lending.groupby(\"region\").size())\n",
        "print(\"------------------\")\n",
        "print(lending.groupby(\"state\").size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "region\n",
            "Midwest      13290\n",
            "Northeast    17546\n",
            "South        30513\n",
            "West         19754\n",
            "dtype: int64\n",
            "------------------\n",
            "state\n",
            "AK      210\n",
            "AL     1399\n",
            "AR      999\n",
            "AZ     1747\n",
            "CA    11128\n",
            "CO     1459\n",
            "CT     1325\n",
            "DC      209\n",
            "DE      285\n",
            "FL     6299\n",
            "GA     3061\n",
            "HI      473\n",
            "IA       11\n",
            "ID        7\n",
            "IL     3403\n",
            "IN      113\n",
            "KS      670\n",
            "KY     1106\n",
            "LA     1138\n",
            "MA     2115\n",
            "MD     1907\n",
            "ME        8\n",
            "MI     2165\n",
            "MN     1163\n",
            "MO     1539\n",
            "MS       51\n",
            "MT      223\n",
            "NC     2229\n",
            "ND        3\n",
            "NE        9\n",
            "NH      399\n",
            "NJ     2982\n",
            "NM      427\n",
            "NV     1019\n",
            "NY     6577\n",
            "OH     2895\n",
            "OK      866\n",
            "OR      826\n",
            "PA     3561\n",
            "RI      407\n",
            "SC     1285\n",
            "SD      154\n",
            "TN       39\n",
            "TX     6566\n",
            "UT      540\n",
            "VA     2557\n",
            "VT      172\n",
            "WA     1529\n",
            "WI     1165\n",
            "WV      517\n",
            "WY      166\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X7YgYUPF51J",
        "colab_type": "code",
        "outputId": "aead66e5-ac73-4855-c286-b2eea157dd89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Compare the distribution of outcome in different states and regions\n",
        "# Before the transformation, we can found loan requests in IA, NE, and ND were 100% rejected, thus we can build decision tree on that. \n",
        "# However, we can look over \"region\", we can find the difference of \"reject\" and \"accept\" makes more sense.\n",
        "evaluate_split_on_feature(lending, \"state\")\n",
        "evaluate_split_on_feature(lending, \"region\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GA\n",
            "reject    90.23195\n",
            "accept     9.76805\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "CA\n",
            "reject    85.235442\n",
            "accept    14.764558\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "FL\n",
            "reject    89.268138\n",
            "accept    10.731862\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "NJ\n",
            "reject    86.921529\n",
            "accept    13.078471\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "PA\n",
            "reject    90.115136\n",
            "accept     9.884864\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "MN\n",
            "reject    87.962167\n",
            "accept    12.037833\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "KS\n",
            "reject    88.656716\n",
            "accept    11.343284\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "LA\n",
            "reject    91.036907\n",
            "accept     8.963093\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "OR\n",
            "reject    86.924939\n",
            "accept    13.075061\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "MD\n",
            "reject    88.253802\n",
            "accept    11.746198\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "AR\n",
            "reject    93.193193\n",
            "accept     6.806807\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "AZ\n",
            "reject    88.322839\n",
            "accept    11.677161\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "CO\n",
            "reject    88.279644\n",
            "accept    11.720356\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "MT\n",
            "reject    86.547085\n",
            "accept    13.452915\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "MA\n",
            "reject    86.619385\n",
            "accept    13.380615\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "NY\n",
            "reject    86.650449\n",
            "accept    13.349551\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "IL\n",
            "reject    89.803115\n",
            "accept    10.196885\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "TX\n",
            "reject    89.00396\n",
            "accept    10.99604\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "WA\n",
            "reject    87.246566\n",
            "accept    12.753434\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "KY\n",
            "reject    92.585895\n",
            "accept     7.414105\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "OH\n",
            "reject    90.500864\n",
            "accept     9.499136\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "WI\n",
            "reject    90.901288\n",
            "accept     9.098712\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "NC\n",
            "reject    89.950651\n",
            "accept    10.049349\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "CT\n",
            "reject    88.830189\n",
            "accept    11.169811\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "MI\n",
            "reject    91.316397\n",
            "accept     8.683603\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "SC\n",
            "reject    91.906615\n",
            "accept     8.093385\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "VA\n",
            "reject    88.775909\n",
            "accept    11.224091\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "WV\n",
            "reject    91.489362\n",
            "accept     8.510638\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "RI\n",
            "reject    87.469287\n",
            "accept    12.530713\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "AL\n",
            "reject    91.065046\n",
            "accept     8.934954\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "NV\n",
            "reject    86.653582\n",
            "accept    13.346418\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "MO\n",
            "reject    90.188434\n",
            "accept     9.811566\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "OK\n",
            "reject    92.6097\n",
            "accept     7.3903\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "UT\n",
            "reject    90.185185\n",
            "accept     9.814815\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "AK\n",
            "reject    87.619048\n",
            "accept    12.380952\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "HI\n",
            "reject    88.160677\n",
            "accept    11.839323\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "VT\n",
            "reject    90.697674\n",
            "accept     9.302326\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "NH\n",
            "reject    90.47619\n",
            "accept     9.52381\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "NM\n",
            "reject    89.461358\n",
            "accept    10.538642\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "SD\n",
            "reject    85.714286\n",
            "accept    14.285714\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "DE\n",
            "reject    92.631579\n",
            "accept     7.368421\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "DC\n",
            "reject    81.339713\n",
            "accept    18.660287\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "WY\n",
            "reject    83.13253\n",
            "accept    16.86747\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "MS\n",
            "reject    92.156863\n",
            "accept     7.843137\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "ID\n",
            "reject    71.428571\n",
            "accept    28.571429\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "TN\n",
            "reject    97.435897\n",
            "accept     2.564103\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "IN\n",
            "reject    99.115044\n",
            "accept     0.884956\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "ME\n",
            "reject    100.0\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "IA\n",
            "reject    100.0\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "NE\n",
            "reject    100.0\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "ND\n",
            "reject    100.0\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "South\n",
            "reject    89.886278\n",
            "accept    10.113722\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "West\n",
            "reject    86.347069\n",
            "accept    13.652931\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "Northeast\n",
            "reject    87.712299\n",
            "accept    12.287701\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n",
            "Midwest\n",
            "reject    90.173062\n",
            "accept     9.826938\n",
            "Name: outcome, dtype: float64\n",
            "------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn4ai7KAa8Ws",
        "colab_type": "text"
      },
      "source": [
        "### Model comparisons: \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKZT0BC3b4Is",
        "colab_type": "code",
        "outputId": "10e711fb-d4ee-42f6-d162-1691ae8af14d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Create three feature sets\n",
        "original_features = [\"fico\",\"norm_emp_length\"]\n",
        "state_impact = [\"fico\",\"norm_emp_length\",\"state\"]\n",
        "region_impact = [\"fico\",\"norm_emp_length\",\"region\"]\n",
        "\n",
        "feature_sets = {\n",
        "    \"original\": original_features,\n",
        "    \"original+state\": state_impact,\n",
        "    \"original+region\": region_impact\n",
        "}\n",
        "\n",
        "# We can check whether the variable transformation makes a positive impact on model performance or not\n",
        "\n",
        "best = 0\n",
        "best_name = None\n",
        "best_actual = None\n",
        "best_predictions = None\n",
        "\n",
        "precisions = []\n",
        "recalls = []\n",
        "kappas = []\n",
        "accuracies = []\n",
        "\n",
        "predictions = {}\n",
        "actual = None\n",
        "\n",
        "# For each feature set, we evaluate our model on both the train and the test set\n",
        "for set_name, feature_set in feature_sets.items():\n",
        "\n",
        "    # Create a dummyset with only the features in our feature set\n",
        "    X = lending.loc[:, feature_set]\n",
        "    X = pd.get_dummies(X)\n",
        "\n",
        "    y = lending[\"loan_outcome\"]\n",
        "\n",
        "    # Use scikit-learn to create our train/test split and train our decision tree\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=123)\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", random_state=123).fit(X_train, y_train)\n",
        "\n",
        "    # Calculate our accuracy on the train and test sets\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = 100*accuracy_score(y_test, y_pred)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "\n",
        "    metric_to_optimize = accuracy\n",
        "    \n",
        "    if metric_to_optimize > best:\n",
        "        best = metric_to_optimize\n",
        "        best_name = set_name\n",
        "        best_actual = y_test\n",
        "        best_predictions = y_pred\n",
        "        \n",
        "    predictions[set_name] = y_pred\n",
        "    actual = np.array(list(y_test))\n",
        "    \n",
        "    # Bookkeeping and printing for the reader (not part of the core loop)\n",
        "    print(f\"Results for {set_name}:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(f\"Accuracy: {accuracy:.1f} Kappa: {kappa:.3f} Precision: {precision:.3f} Recall: {recall:.3f} \\n\")\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    kappas.append(kappa)\n",
        "    accuracies.append(accuracy)\n",
        "    print(\"------------------------\")\n",
        "    \n",
        "print(f\"Best feature set is: {best_name} \\nWith: {best:.1f}% accuracy.\")    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for original:\n",
            "[[13979   370]\n",
            " [  197  1675]]\n",
            "Accuracy: 96.5 Kappa: 0.835 Precision: 0.819 Recall: 0.895 \n",
            "\n",
            "------------------------\n",
            "Results for original+state:\n",
            "[[13967   382]\n",
            " [  253  1619]]\n",
            "Accuracy: 96.1 Kappa: 0.814 Precision: 0.809 Recall: 0.865 \n",
            "\n",
            "------------------------\n",
            "Results for original+region:\n",
            "[[13964   385]\n",
            " [  195  1677]]\n",
            "Accuracy: 96.4 Kappa: 0.832 Precision: 0.813 Recall: 0.896 \n",
            "\n",
            "------------------------\n",
            "Best feature set is: original \n",
            "With: 96.5% accuracy.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4n1DmSwFmAQ",
        "colab_type": "text"
      },
      "source": [
        "##2. Create a new feature: emp_length_numeric\n",
        "\n",
        "\n",
        "\n",
        "*   In the Homework 1, I created a new variable called “norm_emp_length” with two labels: short employment (employment length is less than 1 year) and long employment (employment length is more than 1 year). Here, I create the a new variable “emp_length_numeric” and directly use number to represent employment length: “< 1 year” is labeled as “0” while “10+ years” is labeled as “10”. Others are labeled directly same as its employment length. \n",
        "\n",
        "\n",
        "*   As for the difference between the two approaches of representing the employment length, the accuracy is exactly the same! To some extent, those two approaches have the same capability of making predictions. However, the score of recall in the model with original feature set is higher, which indicates that more actual accepted loans have better precisely predicted, thus, still, **the original approach of representing employment length seems better**. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0ItGOnR-qF6",
        "colab_type": "code",
        "outputId": "a5e406c4-6d86-42ce-8075-da9c2e9a2bbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "def emp_length_numeric(x):\n",
        "    if x == \"< 1 year\":\n",
        "        return 0\n",
        "    if x ==  \"1 year\":\n",
        "        return 1\n",
        "    if x ==  \"2 years\":\n",
        "        return 2\n",
        "    if x ==  \"3 years\":\n",
        "        return 3\n",
        "    if x ==  \"4 years\":\n",
        "        return 4\n",
        "    if x ==  \"5 years\":\n",
        "        return 5\n",
        "    if x ==  \"6 years\":\n",
        "        return 6\n",
        "    if x ==  \"7 years\":\n",
        "        return 7\n",
        "    if x ==  \"8 years\":\n",
        "        return 8\n",
        "    if x ==  \"9 years\":\n",
        "        return 9\n",
        "    if x ==  \"10+ years\":\n",
        "        return 10\n",
        "    \n",
        "lending[\"emp_length_numeric\"] = lending[\"emp_length\"].apply(emp_length_numeric)\n",
        "lending[\"emp_length_numeric\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     57065\n",
              "10     5959\n",
              "2      3362\n",
              "1      2963\n",
              "3      2690\n",
              "4      2175\n",
              "5      2135\n",
              "6      1627\n",
              "7      1243\n",
              "8      1054\n",
              "9       830\n",
              "Name: emp_length_numeric, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHi_uUEgg3FB",
        "colab_type": "text"
      },
      "source": [
        "### Model comparisons: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dhz86OmugrJk",
        "colab_type": "code",
        "outputId": "5a7311a9-34ec-4731-ce1a-fb0c219226d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Create two feature sets with different forms of employment length\n",
        "original_features = [\"fico\",\"norm_emp_length\"]\n",
        "new_features = [\"fico\",\"emp_length_numeric\"]\n",
        "\n",
        "\n",
        "feature_sets = {\n",
        "    \"original\": original_features,\n",
        "    \"new\": new_features\n",
        "}\n",
        "\n",
        "# We can check whether the variable transformation makes a positive impact on model performance or not\n",
        "\n",
        "best = 0\n",
        "best_name = None\n",
        "best_actual = None\n",
        "best_predictions = None\n",
        "\n",
        "precisions = []\n",
        "recalls = []\n",
        "kappas = []\n",
        "accuracies = []\n",
        "\n",
        "predictions = {}\n",
        "actual = None\n",
        "\n",
        "# For each feature set, we evaluate our model on both the train and the test set\n",
        "for set_name, feature_set in feature_sets.items():\n",
        "\n",
        "    # Create a dummyset with only the features in our feature set\n",
        "    X = lending.loc[:, feature_set]\n",
        "    X = pd.get_dummies(X)\n",
        "\n",
        "    y = lending[\"loan_outcome\"]\n",
        "\n",
        "    # Use scikit-learn to create our train/test split and train our decision tree\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=123)\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", random_state=123).fit(X_train, y_train)\n",
        "\n",
        "    # Calculate our accuracy on the train and test sets\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = 100*accuracy_score(y_test, y_pred)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "\n",
        "    metric_to_optimize = accuracy\n",
        "    \n",
        "    if metric_to_optimize > best:\n",
        "        best = metric_to_optimize\n",
        "        best_name = set_name\n",
        "        best_actual = y_test\n",
        "        best_predictions = y_pred\n",
        "        \n",
        "    predictions[set_name] = y_pred\n",
        "    actual = np.array(list(y_test))\n",
        "    \n",
        "    # Bookkeeping and printing for the reader (not part of the core loop)\n",
        "    print(f\"Results for {set_name}:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(f\"Accuracy: {accuracy:.1f} Kappa: {kappa:.3f} Precision: {precision:.3f} Recall: {recall:.3f} \\n\")\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    kappas.append(kappa)\n",
        "    accuracies.append(accuracy)\n",
        "    print(\"------------------------\")\n",
        "    \n",
        "print(f\"Best feature set is: {best_name} \\nWith: {best:.1f}% accuracy.\")    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for original:\n",
            "[[13979   370]\n",
            " [  197  1675]]\n",
            "Accuracy: 96.5 Kappa: 0.835 Precision: 0.819 Recall: 0.895 \n",
            "\n",
            "------------------------\n",
            "Results for new:\n",
            "[[13980   369]\n",
            " [  205  1667]]\n",
            "Accuracy: 96.5 Kappa: 0.833 Precision: 0.819 Recall: 0.890 \n",
            "\n",
            "------------------------\n",
            "Best feature set is: original \n",
            "With: 96.5% accuracy.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxrMytfnR0nP",
        "colab_type": "text"
      },
      "source": [
        "## 3. Create a new feature: intention\n",
        "\n",
        "*   First of all, I referred to the dropdown list of the “What’s the money for” on the website of [LendingClub](https://www.lendingclub.com), so that I can extract the key words to summarize the types.\n",
        "\n",
        "\n",
        "*   Therefore, I create a new feature called \"intention\" with **8** labels to summarized the types of loans:\n",
        "1.   refinance credit cards\n",
        "2.   consolidate debt\n",
        "3.   accommodation (including purchase home, improve home, pay to move or relocate)\n",
        "4.   refinance car\n",
        "5.   finance business\n",
        "6.   cover medical expenses\n",
        "7.   other personal issues\n",
        "8.   other issues (including buy something special, pay for a vacation, fund a green loan, and not listed here)\n",
        "\n",
        "*   As for the model comparisons, **the model with original feature set plus “title” performs the best**. However, I don’t think this feature transformation is unnecessary. Since we don’t want to overfit, I still would like to use “intention” in the following processes of optimization and to make comparisons. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf-0wXqB_rn3",
        "colab_type": "code",
        "outputId": "56341f66-b403-4fd7-ab2b-44f5dd52fa32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# define the function to create \"intention\"\n",
        "def set_intention(x):\n",
        "  if \"Credit\" in str(x) or \"credit\" in str(x) or \"CREDIT\" in str(x):\n",
        "    return \"refinance credit cards\"\n",
        "  if \"Consolidation\" in str(x) or \"consolidation\" in str(x) or \"CONSOLIDATION\" in str(x):\n",
        "    return \"consolidate debt\"\n",
        "  if \"Home\" in str(x) or \"home\" in str(x) or \"HOME\" in str(x) or \"move\" in str(x) or \"relocate\" in str(x):\n",
        "    return \"accommodation\"\n",
        "  if \"Car\" in str(x) or \"car\" in str(x) or \"CAR\" in str(x):\n",
        "    return \"refinance car\"\n",
        "  if \"Business\" in str(x) or \"business\" in str(x) or \"BUSINESS\" in str(x) or \"start up\" in str(x):\n",
        "    return \"finance business\"\n",
        "  if \"Medi\" in str(x) or \"medi\" in str(x) or \"MEDI\" in str(x):\n",
        "    return \"cover medical expenses\"\n",
        "  if \"other\" in str(x):\n",
        "    return \"other personal issues\"\n",
        "  else:\n",
        "    return \"other issues\"\n",
        "\n",
        "lending[\"intention\"] = lending[\"title\"].apply(set_intention)\n",
        "lending[\"intention\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "consolidate debt          27747\n",
              "other issues              21084\n",
              "other personal issues      8902\n",
              "refinance credit cards     7396\n",
              "accommodation              4908\n",
              "refinance car              4618\n",
              "finance business           4420\n",
              "cover medical expenses     2028\n",
              "Name: intention, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkiPhBnAmSNq",
        "colab_type": "text"
      },
      "source": [
        "### Model comparisons: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsl_VfSUmRsC",
        "colab_type": "code",
        "outputId": "2c4cc1ae-56e7-48e9-dd53-8301f30f5136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Create two feature sets with different forms of employment length\n",
        "original_features = [\"fico\",\"norm_emp_length\"]\n",
        "with_title = [\"fico\",\"norm_emp_length\", \"title\"]\n",
        "with_intention = [\"fico\",\"norm_emp_length\", \"intention\"]\n",
        "\n",
        "\n",
        "feature_sets = {\n",
        "    \"original\": original_features,\n",
        "    \"with_title\": with_title,\n",
        "    \"with_intention\" : with_intention\n",
        "}\n",
        "\n",
        "# We can check whether the variable transformation makes a positive impact on model performance or not\n",
        "\n",
        "best = 0\n",
        "best_name = None\n",
        "best_actual = None\n",
        "best_predictions = None\n",
        "\n",
        "precisions = []\n",
        "recalls = []\n",
        "kappas = []\n",
        "accuracies = []\n",
        "\n",
        "predictions = {}\n",
        "actual = None\n",
        "\n",
        "# For each feature set, we evaluate our model on both the train and the test set\n",
        "for set_name, feature_set in feature_sets.items():\n",
        "\n",
        "    # Create a dummyset with only the features in our feature set\n",
        "    X = lending.loc[:, feature_set]\n",
        "    X = pd.get_dummies(X)\n",
        "\n",
        "    y = lending[\"loan_outcome\"]\n",
        "\n",
        "    # Use scikit-learn to create our train/test split and train our decision tree\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=123)\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", random_state=123).fit(X_train, y_train)\n",
        "\n",
        "    # Calculate our accuracy on the train and test sets\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = 100*accuracy_score(y_test, y_pred)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "\n",
        "    metric_to_optimize = accuracy\n",
        "    \n",
        "    if metric_to_optimize > best:\n",
        "        best = metric_to_optimize\n",
        "        best_name = set_name\n",
        "        best_actual = y_test\n",
        "        best_predictions = y_pred\n",
        "        \n",
        "    predictions[set_name] = y_pred\n",
        "    actual = np.array(list(y_test))\n",
        "    \n",
        "    # Bookkeeping and printing for the reader (not part of the core loop)\n",
        "    print(f\"Results for {set_name}:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(f\"Accuracy: {accuracy:.1f} Kappa: {kappa:.3f} Precision: {precision:.3f} Recall: {recall:.3f} \\n\")\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    kappas.append(kappa)\n",
        "    accuracies.append(accuracy)\n",
        "    print(\"------------------------\")\n",
        "    \n",
        "print(f\"Best feature set is: {best_name} \\nWith: {best:.1f}% accuracy.\")    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for original:\n",
            "[[13979   370]\n",
            " [  197  1675]]\n",
            "Accuracy: 96.5 Kappa: 0.835 Precision: 0.819 Recall: 0.895 \n",
            "\n",
            "------------------------\n",
            "Results for with_title:\n",
            "[[14120   229]\n",
            " [   49  1823]]\n",
            "Accuracy: 98.3 Kappa: 0.919 Precision: 0.888 Recall: 0.974 \n",
            "\n",
            "------------------------\n",
            "Results for with_intention:\n",
            "[[14001   348]\n",
            " [  215  1657]]\n",
            "Accuracy: 96.5 Kappa: 0.835 Precision: 0.826 Recall: 0.885 \n",
            "\n",
            "------------------------\n",
            "Best feature set is: with_title \n",
            "With: 98.3% accuracy.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRLUt_wfmwxM",
        "colab_type": "text"
      },
      "source": [
        "##  A General Summary for Question 1:\n",
        "*   For Question 1, I tried to accomplish the **three options**. \n",
        "*   In general, the performance of the model with the original feature set (“fico”, “norm_emp_length”) is pretty good. \n",
        "*   The model with the feature “region” is better than the model with the feature “state”.\n",
        "*   The model with the feature “emp_length_numeric” is as good as the original model, but the score of recall is slightly higher in the original model. \n",
        "*   The model with the feature “intention” is not better than the model with the feature “title”. \n",
        "*   Therefore, the features \"region\", \"norm_emp_length\",\"title\", and \"intention\" will be used in the second option in Question 2.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVQ3tJhgExhL",
        "colab_type": "code",
        "outputId": "6c5f30a6-4680-42d1-cde0-3053c7cacea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "# Finally, check dataset with three new features now.\n",
        "lending.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>amount</th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>fico</th>\n",
              "      <th>dti</th>\n",
              "      <th>zip</th>\n",
              "      <th>state</th>\n",
              "      <th>emp_length</th>\n",
              "      <th>policy_code</th>\n",
              "      <th>year</th>\n",
              "      <th>outcome</th>\n",
              "      <th>loan_outcome</th>\n",
              "      <th>norm_emp_length</th>\n",
              "      <th>region</th>\n",
              "      <th>emp_length_numeric</th>\n",
              "      <th>intention</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2500.0</td>\n",
              "      <td>Dec-2011</td>\n",
              "      <td>bike</td>\n",
              "      <td>740.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>309xx</td>\n",
              "      <td>GA</td>\n",
              "      <td>&lt; 1 year</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>accept</td>\n",
              "      <td>True</td>\n",
              "      <td>short employment</td>\n",
              "      <td>South</td>\n",
              "      <td>0</td>\n",
              "      <td>other issues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12000.0</td>\n",
              "      <td>Dec-2011</td>\n",
              "      <td>Consolidation</td>\n",
              "      <td>675.0</td>\n",
              "      <td>10.78</td>\n",
              "      <td>913xx</td>\n",
              "      <td>CA</td>\n",
              "      <td>10+ years</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>accept</td>\n",
              "      <td>True</td>\n",
              "      <td>long employment</td>\n",
              "      <td>West</td>\n",
              "      <td>10</td>\n",
              "      <td>consolidate debt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21000.0</td>\n",
              "      <td>Dec-2011</td>\n",
              "      <td>Debt Cleanup</td>\n",
              "      <td>705.0</td>\n",
              "      <td>13.22</td>\n",
              "      <td>335xx</td>\n",
              "      <td>FL</td>\n",
              "      <td>10+ years</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>accept</td>\n",
              "      <td>True</td>\n",
              "      <td>long employment</td>\n",
              "      <td>South</td>\n",
              "      <td>10</td>\n",
              "      <td>other issues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31825.0</td>\n",
              "      <td>Dec-2011</td>\n",
              "      <td>Debt Consolidation Loan</td>\n",
              "      <td>760.0</td>\n",
              "      <td>14.03</td>\n",
              "      <td>080xx</td>\n",
              "      <td>NJ</td>\n",
              "      <td>5 years</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>accept</td>\n",
              "      <td>True</td>\n",
              "      <td>long employment</td>\n",
              "      <td>Northeast</td>\n",
              "      <td>5</td>\n",
              "      <td>consolidate debt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12000.0</td>\n",
              "      <td>Dec-2011</td>\n",
              "      <td>Debt Consolidation</td>\n",
              "      <td>725.0</td>\n",
              "      <td>16.70</td>\n",
              "      <td>088xx</td>\n",
              "      <td>NJ</td>\n",
              "      <td>10+ years</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>accept</td>\n",
              "      <td>True</td>\n",
              "      <td>long employment</td>\n",
              "      <td>Northeast</td>\n",
              "      <td>10</td>\n",
              "      <td>consolidate debt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    amount      date  ... emp_length_numeric         intention\n",
              "0   2500.0  Dec-2011  ...                  0      other issues\n",
              "1  12000.0  Dec-2011  ...                 10  consolidate debt\n",
              "2  21000.0  Dec-2011  ...                 10      other issues\n",
              "3  31825.0  Dec-2011  ...                  5  consolidate debt\n",
              "4  12000.0  Dec-2011  ...                 10  consolidate debt\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S-tYM8YGHOg",
        "colab_type": "text"
      },
      "source": [
        "# **Answer to Question 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKLACxhRMOrz",
        "colab_type": "text"
      },
      "source": [
        "### 1. Amount of data available for training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oqdHGQPc4uw",
        "colab_type": "text"
      },
      "source": [
        "#### Create models with different amounts of data available for training.\n",
        "*   Still, I used scikit_learn's built in function to split the training set and test set. We can change the parameter of \"test_size\" to change the amount of data for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTXN9C8hzWLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a parameter set for \"test_size\"\n",
        "\n",
        "test_size = {\n",
        "    \"Train/Test (extreme) = 0.99/0.01\" : 0.01,\n",
        "    \"Train/Test = 0.9/0.1\" : 0.1,\n",
        "    \"Train/Test = 0.8/0.2\" : 0.2,\n",
        "    \"Train/Test = 0.7/0.3\" : 0.3,\n",
        "    \"Train/Test = 0.6/0.4\" : 0.4,\n",
        "    \"Train/Test = 0.5/0.5\" : 0.5,\n",
        "    \"Train/Test = 0.4/0.6\" : 0.6,\n",
        "    \"Train/Test = 0.3/0.7\" : 0.7,\n",
        "    \"Train/Test = 0.2/0.8\" : 0.8,\n",
        "    \"Train/Test = 0.1/0.9\" : 0.9,\n",
        "    \"Train/Test (extreme) = 0.01/0.99\" : 0.99\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar9wtN0NxqOL",
        "colab_type": "code",
        "outputId": "db646961-bc48-4ce4-f5c4-322d6ee15a88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "predictions = {}\n",
        "actual = None\n",
        "\n",
        "# create the original feature set\n",
        "original_features = [\"fico\",\"norm_emp_length\"]\n",
        "\n",
        "# Create a dummyset with only the features in our feature set\n",
        "X = lending.loc[:, original_features]\n",
        "X = pd.get_dummies(X)\n",
        "y = lending[\"loan_outcome\"]\n",
        "\n",
        "for set_name, para in test_size.items():\n",
        "  # Use scikit-learn to create train/test split and train our decision tree\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = para, random_state=123)\n",
        "  model = DecisionTreeClassifier(criterion=\"entropy\", random_state=123).fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  # Calculate quality metrics\n",
        "  accuracy = 100*accuracy_score(y_test, y_pred)\n",
        "  kappa = cohen_kappa_score(y_test, y_pred)\n",
        "  precision = precision_score(y_test, y_pred)\n",
        "  recall = recall_score(y_test, y_pred)\n",
        "\n",
        "  predictions[set_name] = y_pred\n",
        "  actual = np.array(list(y_test))\n",
        "  \n",
        "  print(f\"Results for {set_name}:\")\n",
        "  print(confusion_matrix(y_test, y_pred))\n",
        "  print(f\"\\nThe quality metrics are as follow: \\nAccuracy: {accuracy:.1f}% Kappa: {kappa:.3f} Precision: {precision:.3f} Recall: {recall:.3f} \\n\")\n",
        "  print(f\"In this model, tree contains {model.get_n_leaves()} leaves\")\n",
        "  print(f\"In this model, the depth of tree is {model.get_depth()}\")\n",
        "  print(\"---------------------------- \\n\")\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for Train/Test (extreme) = 0.99/0.01:\n",
            "[[705  11]\n",
            " [ 13  83]]\n",
            "\n",
            "The quality metrics are as follow: \n",
            "Accuracy: 97.0% Kappa: 0.857 Precision: 0.883 Recall: 0.865 \n",
            "\n",
            "In this model, tree contains 150 leaves\n",
            "In this model, the depth of tree is 69\n",
            "---------------------------- \n",
            "\n",
            "Results for Train/Test = 0.9/0.1:\n",
            "[[6965  193]\n",
            " [  97  856]]\n",
            "\n",
            "The quality metrics are as follow: \n",
            "Accuracy: 96.4% Kappa: 0.835 Precision: 0.816 Recall: 0.898 \n",
            "\n",
            "In this model, tree contains 148 leaves\n",
            "In this model, the depth of tree is 69\n",
            "---------------------------- \n",
            "\n",
            "Results for Train/Test = 0.8/0.2:\n",
            "[[13979   370]\n",
            " [  197  1675]]\n",
            "\n",
            "The quality metrics are as follow: \n",
            "Accuracy: 96.5% Kappa: 0.835 Precision: 0.819 Recall: 0.895 \n",
            "\n",
            "In this model, tree contains 148 leaves\n",
            "In this model, the depth of tree is 69\n",
            "---------------------------- \n",
            "\n",
            "Results for Train/Test = 0.7/0.3:\n",
            "[[20964   548]\n",
            " [  289  2530]]\n",
            "\n",
            "The quality metrics are as follow: \n",
            "Accuracy: 96.6% Kappa: 0.839 Precision: 0.822 Recall: 0.897 \n",
            "\n",
            "In this model, tree contains 146 leaves\n",
            "In this model, the depth of tree is 67\n",
            "---------------------------- \n",
            "\n",
            "Results for Train/Test = 0.6/0.4:\n",
            "[[27974   732]\n",
            " [  372  3364]]\n",
            "\n",
            "The quality metrics are as follow: \n",
            "Accuracy: 96.6% Kappa: 0.840 Precision: 0.821 Recall: 0.900 \n",
            "\n",
            "In this model, tree contains 146 leaves\n",
            "In this model, the depth of tree is 71\n",
            "---------------------------- \n",
            "\n",
            "Results for Train/Test = 0.5/0.5:\n",
            "[[34969   943]\n",
            " [  446  4194]]\n",
            "\n",
            "The quality metrics are as follow: \n",
            "Accuracy: 96.6% Kappa: 0.839 Precision: 0.816 Recall: 0.904 \n",
            "\n",
            "In this model, tree contains 146 leaves\n",
            "In this model, the depth of tree is 69\n",
            "---------------------------- \n",
            "\n",
            "Results for Train/Test = 0.4/0.6:\n",
            "[[41977  1156]\n",
            " [  532  4997]]\n",
            "\n",
            "The quality metrics are as follow: \n",
            "Accuracy: 96.5% Kappa: 0.836 Precision: 0.812 Recall: 0.904 \n",
            "\n",
            "In this model, tree contains 146 leaves\n",
            "In this model, the depth of tree is 66\n",
            "---------------------------- \n",
            "\n",
            "Results for Train/Test = 0.3/0.7:\n",
            "[[48949  1378]\n",
            " [  635  5811]]\n",
            "\n",
            "The quality metrics are as follow: \n",
            "Accuracy: 96.5% Kappa: 0.832 Precision: 0.808 Recall: 0.901 \n",
            "\n",
            "In this model, tree contains 140 leaves\n",
            "In this model, the depth of tree is 61\n",
            "---------------------------- \n",
            "\n",
            "Results for Train/Test = 0.2/0.8:\n",
            "[[55939  1580]\n",
            " [  732  6632]]\n",
            "\n",
            "The quality metrics are as follow: \n",
            "Accuracy: 96.4% Kappa: 0.831 Precision: 0.808 Recall: 0.901 \n",
            "\n",
            "In this model, tree contains 130 leaves\n",
            "In this model, the depth of tree is 64\n",
            "---------------------------- \n",
            "\n",
            "Results for Train/Test = 0.1/0.9:\n",
            "[[62886  1805]\n",
            " [  831  7471]]\n",
            "\n",
            "The quality metrics are as follow: \n",
            "Accuracy: 96.4% Kappa: 0.830 Precision: 0.805 Recall: 0.900 \n",
            "\n",
            "In this model, tree contains 116 leaves\n",
            "In this model, the depth of tree is 57\n",
            "---------------------------- \n",
            "\n",
            "Results for Train/Test (extreme) = 0.01/0.99:\n",
            "[[67849  3291]\n",
            " [ 1652  7500]]\n",
            "\n",
            "The quality metrics are as follow: \n",
            "Accuracy: 93.8% Kappa: 0.717 Precision: 0.695 Recall: 0.819 \n",
            "\n",
            "In this model, tree contains 61 leaves\n",
            "In this model, the depth of tree is 24\n",
            "---------------------------- \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6_1wyBx2qf-",
        "colab_type": "text"
      },
      "source": [
        "#### Results by Train/Test Amounts:\n",
        "\n",
        "\n",
        "|Train/Test|Accuracy|Leaf Amount|Tree Depth|\n",
        "|----------|--------|-----------|-----------|\n",
        "|0.99/0.01 | **97.0%**  |      150  |       69  |\n",
        "|0.9/0.1   | 96.4%  |      148  |       69  |\n",
        "|0.8/0.2   | 96.5%  |      148  |       69  |\n",
        "|0.7/0.3   | 96.6%  |      146  |       67  |\n",
        "|0.6/0.4   | 96.6%  |      146  |       71  |\n",
        "|0.5/0.5   | 96.6%  |      146  |       69  |\n",
        "|0.4/0.6   | 96.5%  |      146  |       66  |\n",
        "|0.3/0.7   | 96.5%  |      140  |       61  |\n",
        "|0.2/0.8   | 96.4%  |      130  |       64  |\n",
        "|0.1/0.9   | 96.4%  |      116  |       57  |\n",
        "|0.01/0.99 | 93.8%  |      61   |       24  |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3qRpx46CPZU",
        "colab_type": "text"
      },
      "source": [
        "### 2. Subset of features included in the model.\n",
        "\n",
        "\n",
        "*   Here, I created 16 sub-feature sets to compare the accuracy. Based on the outcomes, the feature set including \"fico\", \"norm_emp_length\", \"region\", \"title\" performs the best. \n",
        "*   Based on the summary of statistical significance of difference, the feature \"intention\" cannot make a significant difference on the model when it combines with those original features. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wzi9aK9SCOPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create feature sets with 16 sub-feature sets\n",
        "\n",
        "original = [\"fico\",\"norm_emp_length\"] \n",
        "debt_pressures = [\"dti\",\"amount\"] \n",
        "region= [\"region\"]\n",
        "title = [\"title\"]\n",
        "intention = [\"intention\"] # I continue to use this feature in order to check whether it would contribute to a better performance when it is used with other features\n",
        "\n",
        "feature_sets = {\n",
        "    \"1. original\": original,\n",
        "    \"2. original + debt pressures\": original + debt_pressures,\n",
        "    \"3. original + debt pressures + region\": original + debt_pressures + region,\n",
        "    \"4. original + debt pressures + title\": original + debt_pressures + title,\n",
        "    \"5. original + debt pressures + intention\": original + debt_pressures + intention,\n",
        "    \"6. original + debt pressures + region + title\": original + debt_pressures + region + title,\n",
        "    \"7. original + debt pressures + region + intention\": original + debt_pressures + region + intention,\n",
        "    \"8. original + debt pressures + title + intention\": original + debt_pressures + title + intention,\n",
        "    \"9. original + region\": original + region,\n",
        "    \"10. original + region + title\": original + region + title,\n",
        "    \"11. original + region + intention\": original + region + intention,\n",
        "    \"12. original + region + title + intention\": original + region + title + intention,\n",
        "    \"13. original + title\": original + title,\n",
        "    \"14. original + title+ intention\": original + title + intention,\n",
        "    \"15. original + intention\": original + intention,\n",
        "    \"16. ALL\": original + debt_pressures + region + title + intention\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8r7E_a1Zwnv",
        "colab_type": "code",
        "outputId": "be5f2660-9fd8-4369-8608-8317c7ae8692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# We'll keep track of which classifier was the best\n",
        "best = 0\n",
        "best_name = None\n",
        "best_actual = None\n",
        "best_predictions = None\n",
        "\n",
        "precisions = []\n",
        "recalls = []\n",
        "kappas = []\n",
        "accuracies = []\n",
        "\n",
        "predictions = {}\n",
        "actual = None\n",
        "\n",
        "# For each feature set, we evaluate our model on both the train and the test set\n",
        "for set_name, feature_set in feature_sets.items():\n",
        "\n",
        "    # Create a dummyset with only the features in our feature set\n",
        "    X = lending.loc[:, feature_set]\n",
        "    X = pd.get_dummies(X)\n",
        "\n",
        "    y = lending[\"loan_outcome\"]\n",
        "\n",
        "    # Use scikit-learn to create our train/test split and train our decision tree\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=123)\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", random_state=123).fit(X_train, y_train)\n",
        "\n",
        "    # Calculate our accuracy on the train and test sets\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = 100*accuracy_score(y_test, y_pred)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "\n",
        "    metric_to_optimize = accuracy\n",
        "    \n",
        "    if metric_to_optimize > best:\n",
        "        best = metric_to_optimize\n",
        "        best_name = set_name\n",
        "        best_actual = y_test\n",
        "        best_predictions = y_pred\n",
        "        \n",
        "    predictions[set_name] = y_pred\n",
        "    actual = np.array(list(y_test))\n",
        "    \n",
        "    # Bookkeeping and printing for the reader (not part of the core loop)\n",
        "    print(f\"Results for {set_name}:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(f\"Accuracy: {accuracy:.1f} Kappa: {kappa:.3f} Precision: {precision:.3f} Recall: {recall:.3f} \\n\")\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    kappas.append(kappa)\n",
        "    accuracies.append(accuracy)\n",
        "    print(\"------------------------\")\n",
        "    \n",
        "print(f\"Best feature set is: {best_name} \\nWith: {best:.1f}% accuracy.\")    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for 1. original:\n",
            "[[13979   370]\n",
            " [  197  1675]]\n",
            "Accuracy: 96.5 Kappa: 0.835 Precision: 0.819 Recall: 0.895 \n",
            "\n",
            "------------------------\n",
            "Results for 2. original + debt pressures:\n",
            "[[13921   428]\n",
            " [  415  1457]]\n",
            "Accuracy: 94.8 Kappa: 0.746 Precision: 0.773 Recall: 0.778 \n",
            "\n",
            "------------------------\n",
            "Results for 3. original + debt pressures + region:\n",
            "[[13917   432]\n",
            " [  447  1425]]\n",
            "Accuracy: 94.6 Kappa: 0.734 Precision: 0.767 Recall: 0.761 \n",
            "\n",
            "------------------------\n",
            "Results for 4. original + debt pressures + title:\n",
            "[[13928   421]\n",
            " [  371  1501]]\n",
            "Accuracy: 95.1 Kappa: 0.764 Precision: 0.781 Recall: 0.802 \n",
            "\n",
            "------------------------\n",
            "Results for 5. original + debt pressures + intention:\n",
            "[[13923   426]\n",
            " [  426  1446]]\n",
            "Accuracy: 94.7 Kappa: 0.743 Precision: 0.772 Recall: 0.772 \n",
            "\n",
            "------------------------\n",
            "Results for 6. original + debt pressures + region + title:\n",
            "[[13917   432]\n",
            " [  384  1488]]\n",
            "Accuracy: 95.0 Kappa: 0.756 Precision: 0.775 Recall: 0.795 \n",
            "\n",
            "------------------------\n",
            "Results for 7. original + debt pressures + region + intention:\n",
            "[[13929   420]\n",
            " [  412  1460]]\n",
            "Accuracy: 94.9 Kappa: 0.749 Precision: 0.777 Recall: 0.780 \n",
            "\n",
            "------------------------\n",
            "Results for 8. original + debt pressures + title + intention:\n",
            "[[13885   464]\n",
            " [  405  1467]]\n",
            "Accuracy: 94.6 Kappa: 0.741 Precision: 0.760 Recall: 0.784 \n",
            "\n",
            "------------------------\n",
            "Results for 9. original + region:\n",
            "[[13964   385]\n",
            " [  195  1677]]\n",
            "Accuracy: 96.4 Kappa: 0.832 Precision: 0.813 Recall: 0.896 \n",
            "\n",
            "------------------------\n",
            "Results for 10. original + region + title:\n",
            "[[14117   232]\n",
            " [   51  1821]]\n",
            "Accuracy: 98.3 Kappa: 0.918 Precision: 0.887 Recall: 0.973 \n",
            "\n",
            "------------------------\n",
            "Results for 11. original + region + intention:\n",
            "[[14002   347]\n",
            " [  217  1655]]\n",
            "Accuracy: 96.5 Kappa: 0.835 Precision: 0.827 Recall: 0.884 \n",
            "\n",
            "------------------------\n",
            "Results for 12. original + region + title + intention:\n",
            "[[14092   257]\n",
            " [   89  1783]]\n",
            "Accuracy: 97.9 Kappa: 0.899 Precision: 0.874 Recall: 0.952 \n",
            "\n",
            "------------------------\n",
            "Results for 13. original + title:\n",
            "[[14120   229]\n",
            " [   49  1823]]\n",
            "Accuracy: 98.3 Kappa: 0.919 Precision: 0.888 Recall: 0.974 \n",
            "\n",
            "------------------------\n",
            "Results for 14. original + title+ intention:\n",
            "[[14105   244]\n",
            " [   71  1801]]\n",
            "Accuracy: 98.1 Kappa: 0.909 Precision: 0.881 Recall: 0.962 \n",
            "\n",
            "------------------------\n",
            "Results for 15. original + intention:\n",
            "[[14001   348]\n",
            " [  215  1657]]\n",
            "Accuracy: 96.5 Kappa: 0.835 Precision: 0.826 Recall: 0.885 \n",
            "\n",
            "------------------------\n",
            "Results for 16. ALL:\n",
            "[[13867   482]\n",
            " [  410  1462]]\n",
            "Accuracy: 94.5 Kappa: 0.735 Precision: 0.752 Recall: 0.781 \n",
            "\n",
            "------------------------\n",
            "Best feature set is: 13. original + title \n",
            "With: 98.3% accuracy.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYjfdZCRJ95p",
        "colab_type": "text"
      },
      "source": [
        "#### Check statistical significance of differences among subsets of features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LJ5trp0Hhj5",
        "colab_type": "code",
        "outputId": "16a5a7f7-f40d-4a76-aeeb-9a7e19a2bde3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "matches = {}\n",
        "\n",
        "for feature_set in predictions.keys():\n",
        "    boolean_matches = (predictions[feature_set] == actual)\n",
        "    int_matches = [int(x) for x in boolean_matches]\n",
        "    matches[feature_set] = int_matches\n",
        "\n",
        "for set_a in matches.keys():\n",
        "    for set_b in matches.keys():\n",
        "        if set_a != set_b:\n",
        "            matches_a = matches[set_a]\n",
        "            matches_b = matches[set_b]\n",
        "            t, p = stats.wilcoxon(matches_a, matches_b)\n",
        "            if set_a == \"original\":\n",
        "              print(f\"{set_a} || {set_b}: t={t:.1f}, p={p:.3f}\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original || original + debt pressures: t=85354.5, p=0.000\n",
            "original || original + debt pressures + region: t=93891.0, p=0.000\n",
            "original || original + debt pressures + title: t=172788.0, p=0.000\n",
            "original || original + debt pressures + intention: t=96968.0, p=0.000\n",
            "original || original + debt pressures + region + title: t=188376.0, p=0.000\n",
            "original || original + debt pressures + region + intention: t=110838.0, p=0.000\n",
            "original || original + debt pressures + title + intention: t=212117.5, p=0.000\n",
            "original || original + region: t=78.0, p=0.009\n",
            "original || original + region + title: t=15731.5, p=0.000\n",
            "original || original + region + intention: t=8099.0, p=0.824\n",
            "original || original + region + title + intention: t=28782.0, p=0.000\n",
            "original || original + title: t=14766.0, p=0.000\n",
            "original || original + title+ intention: t=24307.5, p=0.000\n",
            "original || original + intention: t=5364.0, p=0.742\n",
            "original || ALL: t=215670.0, p=0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IWKB6pDbXJq",
        "colab_type": "text"
      },
      "source": [
        "#### Results by Feature Sets:\n",
        "\n",
        "|No.|original|debt pressures|region|title|intention|accuracy|significantly different?|\n",
        "|---|--------|--------------|------|-----|------|-----|----|\n",
        "|1.| X    |      |         |       |  |  96.5 %| Yes|\n",
        "|2.| X    |   X   |         |       |  |94.8   %| Yes|\n",
        "|3.| X    |   X   |    X     |       |  |94.6   %| Yes|\n",
        "|4.| X    |   X   |         |     X  |  |95.1   %| Yes|\n",
        "|5.| X    |   X   |         |       | X |94.7   %| Yes|\n",
        "|6.| X    |   X   |    X     |    X   |  |95.0   %| Yes|\n",
        "|7.| X    |   X   |    X     |       |  X|94.9   %| Yes|\n",
        "|8.| X    |   X   |         |    X   |  X|94.6   %| Yes|\n",
        "| |     |      |         |       |  |   |\n",
        "|9.| X    |      |     X    |       | |96.4   %| Yes|\n",
        "|10.| X    |      |     X    |   X    | |**98.3   %**| Yes|\n",
        "|11.| X    |      |     X    |      |X |96.5   %| **No**|\n",
        "|12.| X    |      |      X   |    X   | X |97.9   %| Yes|\n",
        "|    |      |         |       |  |   |\n",
        "|13.| X    |      |         |  X     |  |**98.3   %**| Yes|\n",
        "|14.| X    |      |         |   X    | X | 98.1  %| Yes|\n",
        "|   |      |         |       |  |   |\n",
        "|15.| X    |      |         |       | X |96.5   %| **No**|\n",
        "|     |      |         |       |  |   |\n",
        "|16.| X    |    X  |    X     |   X    | X | 94.5  %| Yes|\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSdlOqGZCpbA",
        "colab_type": "text"
      },
      "source": [
        "### 3. Decision tree vs. logistic regression classification.\n",
        "\n",
        "*   I find that **decision tree** is better than logistic regression, indicated by the accuracy and ratio of precision and recall. \n",
        "\n",
        "*   Given that the small dataset and only two features used in the prediction, it is reasonable to find decision tree is better. Specifically speaking, decisions tree is often stronger when there are a small number of features that are highly important in making a classification. The features I used here are highly relevant because they can both reflect the borrower’s credit rating level, which would strongly influence the possibility of accepting loans.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2ZJSIx5CeGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a function that takes in the predictions of a classifier, the true labels,\n",
        "# and a set of metrics and displays the model's performance on the metrics\n",
        "\n",
        "def common_evaluations(y_pred, y_actual, metrics, model_name = 'model'):\n",
        "    # Compute Metrics\n",
        "    conf_matrix = confusion_matrix(y_actual, y_pred)\n",
        "    model_results = {}\n",
        "    for (metric_name, metric) in metrics.items():\n",
        "        result = metric(y_actual, y_pred)\n",
        "        model_results[metric_name] = result\n",
        "\n",
        "    # Display Metrics\n",
        "    print(f\"Results for {model_name}:\")\n",
        "    ConfusionMatrixDisplay(conf_matrix, [\"Reject\", \"Accept\"]).plot(values_format='.8g')\n",
        "    plt.show()\n",
        "    print(model_results)\n",
        "    print(\"------------------------\")\n",
        "\n",
        "    return model_results\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTxk8HCfItsv",
        "colab_type": "code",
        "outputId": "37e8b3c4-7528-4448-c90d-7dc07f8b7afe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "# Set a list of two classifiers to compare\n",
        "classifiers = {\n",
        "    \"Decision Tree\"      : DecisionTreeClassifier(criterion=\"entropy\", random_state=123),\n",
        "    \"Logistic Regression\": LogisticRegression(penalty=\"none\", solver=\"lbfgs\", max_iter=10000, random_state=123)\n",
        "}\n",
        "\n",
        "# Set a list of metrics functions \n",
        "metrics = {\n",
        "    \"Accuracy\" : lambda y,y_pred: 100*accuracy_score(y,y_pred),\n",
        "    \"Kappa\"    : cohen_kappa_score,\n",
        "    \"Precision\": precision_score,\n",
        "    \"Recall\"   : recall_score\n",
        "}\n",
        "\n",
        "# Choose a metric to optimize over\n",
        "metric_to_optimize = 'Accuracy'\n",
        "\n",
        "# create the original feature set\n",
        "original = [\"fico\",\"emp_length_numeric\"]\n",
        "\n",
        "\n",
        "# Create our train/test split using this subset of features\n",
        "X = lending.loc[:, original]\n",
        "X = pd.get_dummies(X)\n",
        "y = lending[\"loan_outcome\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=123)\n",
        "\n",
        "# Create variables to keep track of our best model and the metrics for each model\n",
        "best_model_metric = 0\n",
        "best_model_name = None\n",
        "\n",
        "all_model_metrics = {metric: [] for metric in metrics}\n",
        "\n",
        "# For each model in our set of classifiers\n",
        "for classifier_name, classifier in classifiers.items():\n",
        "\n",
        "    # Train the classifier and get its predictions on the test set\n",
        "    model = classifier.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate our metrics on the data \n",
        "    model_results = common_evaluations(y_pred, y_test, metrics, classifier_name)\n",
        "    \n",
        "    # Update our best model if this model is better than our previous best\n",
        "    comparison_metric = model_results[metric_to_optimize]\n",
        "    if comparison_metric > best_model_metric:\n",
        "        best_model_metric = comparison_metric\n",
        "        best_model_name = classifier_name\n",
        "\n",
        "    # Store the metrics for this model\n",
        "    for metric in model_results:\n",
        "        all_model_metrics[metric].append(model_results[metric]) \n",
        "    \n",
        "print(f\"Best classifier is: {best_model_name} \\nWith: {best_model_metric:.1f}% accuracy.\")   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for Decision Tree:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAEGCAYAAAC0DiQ1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'Accuracy': 96.46137722705134, 'Kappa': 0.833045717751856, 'Precision': 0.818762278978389, 'Recall': 0.8904914529914529}\n",
            "------------------------\n",
            "Results for Logistic Regression:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAEGCAYAAAC0DiQ1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'Accuracy': 88.53338265211762, 'Kappa': 0.2853653895266054, 'Precision': 0.5063157894736842, 'Recall': 0.2569444444444444}\n",
            "------------------------\n",
            "Best classifier is: Decision Tree \n",
            "With: 96.5% accuracy.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6U87uPzWHPO",
        "colab_type": "code",
        "outputId": "3fd8be4b-7b86-48e5-8997-3e0ed3d84ef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Make a plot to visualize the difference in precision and recall between two classifers\n",
        "\n",
        "plt.xlim(0,1)\n",
        "plt.xlabel(\"Precision\")\n",
        "plt.ylim(0,1)\n",
        "plt.ylabel(\"Recall\")\n",
        "plt.title(\"Recall vs Precision for Two Classifiers\")\n",
        "\n",
        "# Plot data\n",
        "names = list(classifiers.keys())\n",
        "for i in range(len(classifiers)):\n",
        "    x = all_model_metrics['Precision'][i]\n",
        "    y = all_model_metrics['Recall'][i]\n",
        "    plt.scatter(x, y)\n",
        "    plt.text(x+.01, y+.01, names[i], fontsize=9)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJhbm5Fbe8wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJCYPInd7vBm",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameter tuning for the best-performing model from option 3\n",
        "\n",
        "*   Based on the analysis above, I continue to optimize the decision tree classifier. Here, I just used Scikit-learn’s built-in library tools to tune three hyperparameters together:\n",
        "> 1.   purity criterion: \"gini\", \"entropy\"\n",
        "> 2.   purity threshold: \"0\", \"0.0001\", \"0.001\", \"0.01\", \"0.1\"\n",
        "> 3.   minimum split size: \"2\",\"4\",\"6\",\"8\",\"10\",\"12\",\"14\",\"16\",\"18\",\"20\"\n",
        "\n",
        "*   After hyperparameter tuning, the accuracy is still 96.5% that is exactly the same to the original model. \n",
        "*   The only different hyperparameter is the purity criterion: the original one employs the “entropy” while the new one employs the “gini”. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D8cv0dmubP3",
        "colab_type": "code",
        "outputId": "74b6fa73-4e3e-443c-8bd6-3c15ed0c8c37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Decide on our features from the data\n",
        "original = [\"fico\",\"norm_emp_length\"]\n",
        "\n",
        "# Prepare our dataset\n",
        "X = lending.loc[:, original]\n",
        "X = pd.get_dummies(X)\n",
        "y = lending[\"loan_outcome\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=123,shuffle=True)\n",
        "\n",
        "\n",
        "# Decide on the hyperparameters we would like to compare\n",
        "hyperparameters = {\n",
        "    \"criterion\":[\"gini\", \"entropy\"],\n",
        "    \"min_impurity_decrease\":[0, 0.0001, 0.001, 0.01, 0.1],\n",
        "    \"min_samples_split\":range(2, 20, 2) \n",
        "}\n",
        "\n",
        "# Initialize a search using cross validation in sklearn\n",
        "search = GridSearchCV(estimator=DecisionTreeClassifier(random_state=123),\n",
        "                            param_grid=hyperparameters, scoring=\"accuracy\")\n",
        "\n",
        "# Train a classifier with each combination of hyperparameters and take the best one\n",
        "# and print out the results\n",
        "classifier = search.fit(X_train, y_train)\n",
        "accuracy = classifier.best_score_\n",
        "best_fit = classifier.best_estimator_\n",
        "print(f\"Best fit when training was {best_fit}\\nWith {100*accuracy:.1f}% accuracy.\")\n",
        "\n",
        "# Evaluate our best model's performance on the test set and print the results\n",
        "y_pred = classifier.predict(X_test)\n",
        "accuracy = 100*accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy on held-out test set: {accuracy:.1f}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best fit when training was DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=123, splitter='best')\n",
            "With 96.5% accuracy.\n",
            "Accuracy on held-out test set: 96.5%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zwONI0Y9oeD",
        "colab_type": "text"
      },
      "source": [
        "## Number of folds or stratification strategy for cross-validation.\n",
        "\n",
        "\n",
        "\n",
        "*   Here, the number of folds is 10.\n",
        "*   The average accuracy among folds is 96.5% that is still equal to the original model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNv2yp_q9s7b",
        "colab_type": "code",
        "outputId": "25617453-280b-4cde-8116-1368d3ee5ffd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Decide on our features from the data\n",
        "original = [\"fico\",\"norm_emp_length\"]\n",
        "\n",
        "# Prepare our dataset\n",
        "X = lending.loc[:, original]\n",
        "X = pd.get_dummies(X)\n",
        "y = lending[\"loan_outcome\"]\n",
        "\n",
        "\n",
        "classifier = DecisionTreeClassifier(criterion=\"entropy\", random_state=123)\n",
        "\n",
        "num_folds = 10 \n",
        "\n",
        "accuracies = []\n",
        "\n",
        "for i in range(num_folds):\n",
        "    X_train = X.loc[X.index % num_folds != i] #index is divisible by zero\n",
        "    X_test = X.loc[X.index % num_folds == i]\n",
        "    y_train = y.loc[y.index % num_folds != i]\n",
        "    y_test = y.loc[y.index % num_folds == i]\n",
        "    \n",
        "    model = classifier.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = 100*accuracy_score(y_test,y_pred)\n",
        "    print(f\"Fold {i}: \\nAccuracy: {accuracy:.1f}% \")\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "avg_accuracy = np.mean(accuracies)\n",
        "print(f\"Average accuracy: {avg_accuracy:.1f}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 0: \n",
            "Accuracy: 96.6% \n",
            "Fold 1: \n",
            "Accuracy: 96.5% \n",
            "Fold 2: \n",
            "Accuracy: 96.6% \n",
            "Fold 3: \n",
            "Accuracy: 96.5% \n",
            "Fold 4: \n",
            "Accuracy: 96.3% \n",
            "Fold 5: \n",
            "Accuracy: 96.4% \n",
            "Fold 6: \n",
            "Accuracy: 96.4% \n",
            "Fold 7: \n",
            "Accuracy: 96.3% \n",
            "Fold 8: \n",
            "Accuracy: 96.6% \n",
            "Fold 9: \n",
            "Accuracy: 96.6% \n",
            "Average accuracy: 96.5%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45JI3b0aJh6W",
        "colab_type": "text"
      },
      "source": [
        "##  A General Summary for Question 2:\n",
        "*  For Question 2, I tried to accomplish the whole **five options**, but seemingly more efforts were made on the former three options. \n",
        "\n",
        "*  In order to rank the impacts on model performance those five options have made, I compare the change of accuracy under different options. The initial accuracy of the decision tree with the original features is 96.5%. Accordingly, the impact rank is as follows:\n",
        "\n",
        "|Rank||Options|Actions|Accuracy increase|\n",
        "|------|-|----------|------|----|\n",
        "|No .1||Change feature subsets|Add the feature “region” and “title”|+1.8%|\n",
        "|No .2||Change the amount of data in training set|change train/test from 0.8/0.2 to 0.99/0.01|+0.5%|\n",
        "|No .3||Hyperparameter tuning|Change purity criterion from entropy to gini|0|\n",
        "|||Change number of folds|Sign folds as 10|0|\n",
        "|No .5||Change model|change to logistic regression|-8.0%|\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOOkWEaIdEWu",
        "colab_type": "text"
      },
      "source": [
        "# **Answer to Question 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_mII26edISl",
        "colab_type": "text"
      },
      "source": [
        "*  Based on the analysis above, the best-performing model is to add “region” and “title” in the feature set, which results in the highest rate of accuracy. \n",
        "\n",
        "*  Let’s look back to the confusion metric of this model:\n",
        "\n",
        "|     |    |  Predictions||\n",
        "|----|----|----|---|\n",
        "||    |     False|      True|\n",
        "|**Actual**|Reject|       14117|        232|\n",
        "      ||Accept|       51|      1821|\n",
        "\n",
        "\n",
        "\n",
        "*  Compared to the original model in the Homework 1, the optimized new model contains more information, so that LendingClub can have a more comprehensive picture of borrower’s success and failure in terms of the loan requests. In this way, LendingClub is able to provide specific assistance for the borrower to increase the possibility of being granted loans. For instance, when LendingClub would like to figure out whether there is a regional discrimination on accepting the loan applications, this model is comparatively informative. \n",
        "\n",
        "*  On the other hand, however, when LendingClub decides to promote the service just at a specific region, the feature “region” might not have a strong influence. Besides, a highest rate of accuracy does not always indicate the best model, especially when we are more concerned about certain minority class. For instance, when we more care about the those accepted applications, we should compare the score of “recall” rather than “accuracy”. In this case, it is worthless to blindly increase accuracy. \n",
        "\n",
        "*  However, as I admitted at the end of my HW1, my original model is too SIMPLE to describe the real situation, thus I believe it is very necessary to add the two features anytime.\n",
        "\n",
        " \n"
      ]
    }
  ]
}
